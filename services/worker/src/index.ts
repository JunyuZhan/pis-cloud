/**
 * PIS Worker - Image Processing Service
 * 
 * @author junyuzhan <junyuzhan@outlook.com>
 * @license MIT
 */

import { config } from 'dotenv';
import { resolve } from 'path';
import { fileURLToPath } from 'url';

// ä»æ ¹ç›®å½•åŠ è½½ .env.localï¼ˆmonorepo ç»Ÿä¸€é…ç½®ï¼‰
const __dirname = fileURLToPath(new URL('.', import.meta.url));
const rootDir = resolve(__dirname, '../../../');
config({ path: resolve(rootDir, '.env.local') });
import http from 'http';
import { Worker, Job, Queue } from 'bullmq';
import { createClient } from '@supabase/supabase-js';
import { connection, QUEUE_NAME, photoQueue } from './lib/redis.js';
import { 
  downloadFile, 
  uploadFile, 
  uploadBuffer,
  initMultipartUpload,
  uploadPart,
  completeMultipartUpload,
  abortMultipartUpload,
  getPresignedGetUrl,
  getPresignedPutUrl,
  listObjects,
  copyFile,
  deleteFile,
  bucketName
} from './lib/storage/index.js';
import { PhotoProcessor } from './processor.js';
import { PackageCreator } from './package-creator.js';

// æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡ (æ”¯æŒä¸¤ç§å˜é‡å)
const supabaseUrl = process.env.SUPABASE_URL || process.env.NEXT_PUBLIC_SUPABASE_URL;
if (!supabaseUrl || !process.env.SUPABASE_SERVICE_ROLE_KEY) {
  console.error('âŒ Missing required environment variables: SUPABASE_URL (or NEXT_PUBLIC_SUPABASE_URL), SUPABASE_SERVICE_ROLE_KEY');
  console.error('   Please configure these values in the root .env.local file');
  process.exit(1);
}

// åˆå§‹åŒ– Supabase å®¢æˆ·ç«¯ (Service Role ç”¨äºåç«¯æ“ä½œ)
const supabase = createClient(
  supabaseUrl,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

interface PhotoJobData {
  photoId: string;
  albumId: string;
  originalKey: string;
}

interface PackageJobData {
  packageId: string;
  albumId: string;
  photoIds: string[];
  includeWatermarked: boolean;
  includeOriginal: boolean;
}

// ============================================
// API è®¤è¯é…ç½®
// ============================================
const WORKER_API_KEY = process.env.WORKER_API_KEY;
if (!WORKER_API_KEY) {
  console.warn('âš ï¸  WORKER_API_KEY not set, API endpoints are unprotected!');
  console.warn('   Please set WORKER_API_KEY in .env.local for production use');
}

// è¯·æ±‚å¤§å°é™åˆ¶
const MAX_BODY_SIZE = 10 * 1024 * 1024; // 10MB for JSON requests
const MAX_UPLOAD_SIZE = 500 * 1024 * 1024; // 500MB for file uploads

// CORS é…ç½®
const CORS_ORIGINS = (process.env.CORS_ORIGINS || '').split(',').filter(Boolean);

/**
 * éªŒè¯ API Key
 */
function authenticateRequest(req: http.IncomingMessage): boolean {
  if (!WORKER_API_KEY) {
    // å¦‚æœæ²¡æœ‰é…ç½® API Keyï¼Œå…è®¸è®¿é—®ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    return true;
  }
  
  const apiKey = req.headers['x-api-key'] || 
                 req.headers['authorization']?.replace(/^Bearer\s+/i, '');
  
  return apiKey === WORKER_API_KEY;
}

/**
 * è®¾ç½® CORS å¤´
 */
function setCorsHeaders(req: http.IncomingMessage, res: http.ServerResponse) {
  const origin = req.headers.origin;
  
  if (CORS_ORIGINS.length > 0 && origin && CORS_ORIGINS.includes(origin)) {
    res.setHeader('Access-Control-Allow-Origin', origin);
  } else if (CORS_ORIGINS.length === 0) {
    // å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰æ¥æº
    res.setHeader('Access-Control-Allow-Origin', '*');
  }
  
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, PUT, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, X-API-Key, Authorization');
}

/**
 * è§£æè¯·æ±‚ä½“ï¼ˆå¸¦å¤§å°é™åˆ¶ï¼‰
 */
function parseRequestBody(
  req: http.IncomingMessage,
  maxSize: number
): Promise<string> {
  return new Promise((resolve, reject) => {
    let body = '';
    let bodySize = 0;
    
    req.on('data', (chunk: Buffer) => {
      bodySize += chunk.length;
      if (bodySize > maxSize) {
        req.destroy();
        reject(new Error(`Request body too large (max: ${maxSize} bytes)`));
        return;
      }
      body += chunk.toString('utf8');
    });
    
    req.on('end', () => {
      resolve(body);
    });
    
    req.on('error', (err) => {
      reject(err);
    });
  });
}

/**
 * è§£æ JSON è¯·æ±‚ä½“ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
 */
async function parseJsonBody(
  req: http.IncomingMessage,
  maxSize: number
): Promise<any> {
  const body = await parseRequestBody(req, maxSize);
  
  try {
    return JSON.parse(body);
  } catch (parseError) {
    throw new Error('Invalid JSON format');
  }
}

console.log('ğŸš€ PIS Worker Starting...');

const worker = new Worker<PhotoJobData>(
  QUEUE_NAME,
  async (job: Job<PhotoJobData>) => {
    const { photoId, albumId, originalKey } = job.data;
    console.log(`[${job.id}] Processing photo ${photoId} for album ${albumId}`);

    try {
      // 0. å…ˆæ£€æŸ¥æ•°æ®åº“è®°å½•æ˜¯å¦å­˜åœ¨ï¼ˆå¯èƒ½åœ¨ä¸Šä¼ å¤±è´¥æ—¶å·²è¢«æ¸…ç†ï¼‰
      const { data: existingPhoto, error: checkError } = await supabase
        .from('photos')
        .select('id, status')
        .eq('id', photoId)
        .single();
      
      // å¦‚æœè®°å½•ä¸å­˜åœ¨ï¼Œè¯´æ˜ä¸Šä¼ å¤±è´¥åå·²è¢«æ¸…ç†ï¼Œç›´æ¥è¿”å›
      if (checkError || !existingPhoto) {
        console.log(`[${job.id}] Photo record not found (likely cleaned up after upload failure), skipping`);
        return; // ä¸æŠ›å‡ºé”™è¯¯ï¼Œé¿å…é‡è¯•
      }
      
      // å¦‚æœçŠ¶æ€å·²ç»æ˜¯ completed æˆ– failedï¼Œè·³è¿‡å¤„ç†
      if (existingPhoto.status === 'completed' || existingPhoto.status === 'failed') {
        console.log(`[${job.id}] Photo already ${existingPhoto.status}, skipping`);
        return;
      }

      // 1. æ›´æ–°çŠ¶æ€ä¸º processing
      const { error: updateError } = await supabase
        .from('photos')
        .update({ status: 'processing' })
        .eq('id', photoId);
      
      // å¦‚æœæ›´æ–°å¤±è´¥ï¼ˆè®°å½•å¯èƒ½å·²è¢«åˆ é™¤ï¼‰ï¼Œç›´æ¥è¿”å›
      if (updateError) {
        console.log(`[${job.id}] Failed to update status (record may have been deleted), skipping`);
        return;
      }

      // 2. ä»å­˜å‚¨ä¸‹è½½åŸå›¾
      // å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯´æ˜ä¸Šä¼ å¤±è´¥ï¼Œä¼šæŠ›å‡º NoSuchKey é”™è¯¯ï¼Œåœ¨ catch ä¸­å¤„ç†
      console.time(`[${job.id}] Download`);
      let originalBuffer: Buffer;
      try {
        originalBuffer = await downloadFile(originalKey);
      } catch (downloadErr: any) {
        // å¦‚æœä¸‹è½½å¤±è´¥ä¸”æ˜¯æ–‡ä»¶ä¸å­˜åœ¨é”™è¯¯ï¼Œæ¸…ç†æ•°æ®åº“è®°å½•
        const isFileNotFound = downloadErr?.code === 'NoSuchKey' || 
                              downloadErr?.message?.includes('does not exist') ||
                              downloadErr?.message?.includes('NoSuchKey');
        
        if (isFileNotFound) {
          console.log(`[${job.id}] File not found during download, cleaning up database record`);
          try {
            await supabase
              .from('photos')
              .delete()
              .eq('id', photoId);
          } catch {
          }
          return; // ä¸æŠ›å‡ºé”™è¯¯ï¼Œé¿å…é‡è¯•
        }
        throw downloadErr; // å…¶ä»–é”™è¯¯ç»§ç»­æŠ›å‡º
      }
      console.timeEnd(`[${job.id}] Download`);

      // 3. è·å–ç…§ç‰‡çš„æ‰‹åŠ¨æ—‹è½¬è§’åº¦
      const { data: photo } = await supabase
        .from('photos')
        .select('rotation')
        .eq('id', photoId)
        .single();

      // 4. è·å–ç›¸å†Œæ°´å°é…ç½®
      const { data: album } = await supabase
        .from('albums')
        .select('watermark_enabled, watermark_type, watermark_config')
        .eq('id', albumId)
        .single();

      // æ„å»ºæ°´å°é…ç½®ï¼ˆæ”¯æŒæ–°æ—§æ ¼å¼ï¼‰
      const watermarkConfigRaw = (album?.watermark_config as any) || {};
      const watermarkConfig = {
        enabled: album?.watermark_enabled ?? false,
        // å¦‚æœåŒ…å« watermarks æ•°ç»„ï¼Œä½¿ç”¨æ–°æ ¼å¼
        watermarks: watermarkConfigRaw.watermarks || undefined,
        // å…¼å®¹æ—§æ ¼å¼
        type: album?.watermark_type ?? watermarkConfigRaw.type ?? 'text',
        text: watermarkConfigRaw.text,
        logoUrl: watermarkConfigRaw.logoUrl,
        opacity: watermarkConfigRaw.opacity ?? 0.5,
        position: watermarkConfigRaw.position ?? 'center',
      };

      // 5. å¤„ç†å›¾ç‰‡ (Sharp)
      console.time(`[${job.id}] Process`);
      const processor = new PhotoProcessor(originalBuffer);
      const result = await processor.process(watermarkConfig, photo?.rotation ?? null);
      console.timeEnd(`[${job.id}] Process`);

      // 6. ä¸Šä¼ å¤„ç†åçš„å›¾ç‰‡åˆ°å­˜å‚¨
      const thumbKey = `processed/thumbs/${albumId}/${photoId}.jpg`;
      const previewKey = `processed/previews/${albumId}/${photoId}.jpg`;

      console.time(`[${job.id}] Upload`);
      await Promise.all([
        uploadFile(thumbKey, result.thumbBuffer, { 'Content-Type': 'image/jpeg' }),
        uploadFile(previewKey, result.previewBuffer, { 'Content-Type': 'image/jpeg' }),
      ]);
      console.timeEnd(`[${job.id}] Upload`);

      // 7. æ›´æ–°æ•°æ®åº“
      const { error } = await supabase
        .from('photos')
        .update({
          status: 'completed',
          thumb_key: thumbKey,
          preview_key: previewKey,
          width: result.metadata.width,
          height: result.metadata.height,
          blur_data: result.blurHash,
          exif: result.exif,
          file_size: originalBuffer.length,
          mime_type: result.metadata.format,
          // å°è¯•ä» EXIF è·å–æ‹æ‘„æ—¶é—´ï¼Œå¦åˆ™ç”¨å½“å‰æ—¶é—´
          captured_at: result.exif?.exif?.DateTimeOriginal || new Date().toISOString(),
          // æ›´æ–°æ—¶é—´æˆ³ï¼ˆç”¨äºå‰ç«¯ç¼“å­˜ç ´åï¼‰
          updated_at: new Date().toISOString(),
        })
        .eq('id', photoId);

      if (error) throw error;

      // 8. ä¼˜åŒ–ï¼šä½¿ç”¨æ•°æ®åº“å‡½æ•°å¢é‡æ›´æ–°ç›¸å†Œç…§ç‰‡æ•°é‡ï¼Œé¿å…æ¯æ¬¡ COUNT æŸ¥è¯¢
      // è¿™æ ·å¯ä»¥å‡å°‘æ•°æ®åº“è´Ÿè½½ï¼Œç‰¹åˆ«æ˜¯åœ¨æ‰¹é‡ä¸Šä¼ æ—¶
      const { error: countError } = await supabase.rpc('increment_photo_count', {
        album_id: albumId
      });
      
      if (countError) {
        // å¦‚æœå‡½æ•°è°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ° COUNT æŸ¥è¯¢ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
        console.warn(`[${job.id}] Failed to use increment_photo_count, falling back to COUNT query:`, countError);
        const { count } = await supabase
          .from('photos')
          .select('*', { count: 'exact', head: true })
          .eq('album_id', albumId)
          .eq('status', 'completed');
        
        await supabase
          .from('albums')
          .update({ photo_count: count || 0 })
          .eq('id', albumId);
      }

      console.log(`[${job.id}] Completed successfully`);
    } catch (err: any) {
      console.error(`[${job.id}] Failed:`, err);
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶ä¸å­˜åœ¨çš„é”™è¯¯ï¼ˆä¸Šä¼ å¤±è´¥ä½†æ•°æ®åº“è®°å½•å·²åˆ›å»ºï¼‰
      const isFileNotFound = err?.code === 'NoSuchKey' || 
                            err?.message?.includes('does not exist') ||
                            err?.message?.includes('NoSuchKey');
      
      if (isFileNotFound) {
        // æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯´æ˜ä¸Šä¼ å¤±è´¥ï¼Œå°è¯•åˆ é™¤æ•°æ®åº“è®°å½•ï¼ˆå¦‚æœè¿˜å­˜åœ¨ï¼‰
        console.log(`[${job.id}] File not found, deleting database record for photo ${photoId}`);
        const { error: deleteError } = await supabase
          .from('photos')
          .delete()
          .eq('id', photoId);
        
        if (deleteError) {
          // è®°å½•å¯èƒ½å·²ç»è¢« cleanup API åˆ é™¤ï¼Œè¿™æ˜¯æ­£å¸¸çš„
          console.log(`[${job.id}] Record may have been already deleted:`, deleteError.message);
        }
        
        // ä¸æŠ›å‡ºé”™è¯¯ï¼Œé¿å…é‡è¯•ï¼ˆæ–‡ä»¶ä¸å­˜åœ¨æ—¶é‡è¯•ä¹Ÿæ²¡ç”¨ï¼‰
        return;
      }
      
      // å…¶ä»–é”™è¯¯ï¼Œæ›´æ–°çŠ¶æ€ä¸º failed
      await supabase
        .from('photos')
        .update({ status: 'failed' })
        .eq('id', photoId);
      
      throw err; // è®© BullMQ çŸ¥é“ä»»åŠ¡å¤±è´¥ (ä»¥ä¾¿é‡è¯•)
    }
  },
  {
    connection,
    concurrency: 5, // é€‚å½“å¢åŠ å¹¶å‘
    limiter: {
      max: 10,
      duration: 1000,
    },
  }
);

worker.on('failed', (job, err) => {
  console.error(`âŒ Job ${job?.id} failed:`, err.message);
});

console.log(`âœ… Worker listening on queue: ${QUEUE_NAME}`);

// ============================================
// æ‰“åŒ…ä¸‹è½½ Worker
// ============================================
const packageQueue = new Queue('package-downloads', { connection });

const packageWorker = new Worker<PackageJobData>(
  'package-downloads',
  async (job: Job<PackageJobData>) => {
    const { packageId, albumId, photoIds, includeWatermarked, includeOriginal } = job.data;
    console.log(`[Package ${job.id}] Processing package ${packageId} for album ${albumId}`);

    try {
      // 1. æ›´æ–°çŠ¶æ€ä¸º processing
      await supabase
        .from('package_downloads')
        .update({ status: 'processing' })
        .eq('id', packageId);

      // 2. è·å–ç›¸å†Œæ°´å°é…ç½®å’Œæ ‡é¢˜
      const { data: album } = await supabase
        .from('albums')
        .select('title, watermark_enabled, watermark_type, watermark_config')
        .eq('id', albumId)
        .single();

      // æ„å»ºæ°´å°é…ç½®ï¼ˆä¸ç…§ç‰‡å¤„ç†é€»è¾‘ä¿æŒä¸€è‡´ï¼Œæ”¯æŒæ–°æ—§æ ¼å¼ï¼‰
      const watermarkConfigRaw = (album?.watermark_config as any) || {};
      const watermarkConfig = album?.watermark_enabled
        ? {
            enabled: true,
            // å¦‚æœåŒ…å« watermarks æ•°ç»„ï¼Œä½¿ç”¨æ–°æ ¼å¼
            watermarks: watermarkConfigRaw.watermarks || undefined,
            // å…¼å®¹æ—§æ ¼å¼
            type: album.watermark_type ?? watermarkConfigRaw.type ?? 'text',
            text: watermarkConfigRaw.text,
            logoUrl: watermarkConfigRaw.logoUrl,
            opacity: watermarkConfigRaw.opacity ?? 0.5,
            position: watermarkConfigRaw.position ?? 'center',
          }
        : undefined;

      // 3. è·å–ç…§ç‰‡ä¿¡æ¯
      const { data: photos } = await supabase
        .from('photos')
        .select('id, filename, original_key, preview_key')
        .in('id', photoIds)
        .eq('status', 'completed');

      if (!photos || photos.length === 0) {
        throw new Error('No photos found');
      }

      // 4. åˆ›å»º ZIP åŒ…
      console.time(`[Package ${job.id}] Create ZIP`);
      const zipBuffer = await PackageCreator.createPackage({
        photos: photos.map(p => ({
          id: p.id,
          filename: p.filename,
          originalKey: p.original_key,
          previewKey: p.preview_key,
        })),
        albumId,
        watermarkConfig,
        includeWatermarked,
        includeOriginal,
      });
      console.timeEnd(`[Package ${job.id}] Create ZIP`);

      // 5. ä¸Šä¼  ZIP åˆ°å­˜å‚¨
      const zipKey = `packages/${albumId}/${packageId}.zip`;
      const albumTitle = (album as any)?.title || 'photos';
      console.time(`[Package ${job.id}] Upload ZIP`);
      await uploadFile(zipKey, zipBuffer, {
        'Content-Type': 'application/zip',
        'Content-Disposition': `attachment; filename="${albumTitle}.zip"`,
      });
      console.timeEnd(`[Package ${job.id}] Upload ZIP`);

      // 6. ç”Ÿæˆä¸‹è½½é“¾æ¥ï¼ˆ15å¤©æœ‰æ•ˆæœŸï¼‰
      const expiresAt = new Date();
      expiresAt.setDate(expiresAt.getDate() + 15);
      const downloadUrl = await getPresignedGetUrl(zipKey, 15 * 24 * 60 * 60); // 15å¤©

      // 7. æ›´æ–°æ•°æ®åº“
      await supabase
        .from('package_downloads')
        .update({
          status: 'completed',
          zip_key: zipKey,
          file_size: zipBuffer.length,
          download_url: downloadUrl,
          expires_at: expiresAt.toISOString(),
          completed_at: new Date().toISOString(),
        })
        .eq('id', packageId);

      console.log(`[Package ${job.id}] Completed successfully`);
    } catch (err: any) {
      console.error(`[Package ${job.id}] Failed:`, err);

      // æ›´æ–°çŠ¶æ€ä¸º failed
      await supabase
        .from('package_downloads')
        .update({ status: 'failed' })
        .eq('id', packageId);

      throw err;
    }
  },
  {
    connection,
    concurrency: 2, // æ‰“åŒ…ä»»åŠ¡å¹¶å‘æ•°è¾ƒä½ï¼Œå› ä¸ºèµ„æºæ¶ˆè€—å¤§
  }
);

packageWorker.on('failed', (job, err) => {
  console.error(`âŒ Package job ${job?.id} failed:`, err.message);
});

console.log(`âœ… Package worker listening on queue: package-downloads`);

// ============================================
// HTTP API æœåŠ¡å™¨ (ç”¨äºæ¥æ”¶ä¸Šä¼ è¯·æ±‚)
// ============================================

const HTTP_PORT = parseInt(process.env.HTTP_PORT || '3001');

const server = http.createServer(async (req, res) => {
  // è®¾ç½® CORS
  setCorsHeaders(req, res);

  if (req.method === 'OPTIONS') {
    res.writeHead(204);
    res.end();
    return;
  }

  const url = new URL(req.url || '/', `http://localhost:${HTTP_PORT}`);

  // å¥åº·æ£€æŸ¥ç«¯ç‚¹ä¸éœ€è¦è®¤è¯
  if (url.pathname === '/health') {
    const health: any = {
      status: 'ok',
      timestamp: new Date().toISOString(),
      services: {}
    };

    // æ£€æŸ¥ Redis è¿æ¥ï¼ˆé€šè¿‡é˜Ÿåˆ—æµ‹è¯•ï¼‰
    try {
      const testQueue = new Queue('health-check', { connection });
      await testQueue.getWaitingCount(); // è½»é‡çº§æ“ä½œæµ‹è¯•è¿æ¥
      await testQueue.close();
      health.services.redis = { status: 'ok' };
    } catch (err: any) {
      health.services.redis = { status: 'error', error: err.message };
      health.status = 'degraded';
    }

    // æ£€æŸ¥ Supabase è¿æ¥
    try {
      const { error } = await supabase.from('albums').select('id').limit(1);
      if (error) throw error;
      health.services.supabase = { status: 'ok' };
    } catch (err: any) {
      health.services.supabase = { status: 'error', error: err.message };
      health.status = 'degraded';
    }

    // æ£€æŸ¥å­˜å‚¨è¿æ¥
    try {
      const storageModule = await import('./lib/storage/index.js');
      const testKey = `health-check-${Date.now()}.txt`;
      // å°è¯•åˆ—å‡º bucketï¼ˆè½»é‡çº§æ“ä½œï¼‰
      health.services.storage = { 
        status: 'ok', 
        bucket: storageModule.bucketName,
        type: process.env.STORAGE_TYPE || 'minio'
      };
    } catch (err: any) {
      health.services.storage = { status: 'error', error: err.message };
      health.status = 'degraded';
    }

    const statusCode = health.status === 'ok' ? 200 : 503;
    res.writeHead(statusCode, { 'Content-Type': 'application/json' });
    res.end(JSON.stringify(health));
    return;
  }

  // API è®¤è¯æ£€æŸ¥ï¼ˆé™¤äº† health ç«¯ç‚¹ï¼‰
  if (!authenticateRequest(req)) {
    res.writeHead(401, { 'Content-Type': 'application/json' });
    res.end(JSON.stringify({ error: 'Unauthorized', message: 'Invalid or missing API key' }));
    return;
  }

  // è·å–é¢„ç­¾åä¸Šä¼  URL (ä¿ç•™å…¼å®¹)
  if (url.pathname === '/api/presign' && req.method === 'POST') {
    try {
      const body = await parseJsonBody(req, MAX_BODY_SIZE);
      const { key } = body;
        if (!key) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing key' }));
          return;
        }

      const presignedUrl = await getPresignedPutUrl(key);
      res.writeHead(200, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ url: presignedUrl }));
    } catch (err: any) {
      console.error('Presign error:', err);
      const statusCode = err.message?.includes('too large') ? 413 : 
                        err.message?.includes('Invalid JSON') ? 400 : 500;
      res.writeHead(statusCode, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: err.message || 'Internal server error' }));
    }
    return;
  }

  // ç›´æ¥ä¸Šä¼ æ–‡ä»¶åˆ° MinIO (ä»£ç†æ¨¡å¼)
  if (url.pathname === '/api/upload' && req.method === 'PUT') {
    const key = url.searchParams.get('key');
    const contentType = req.headers['content-type'] || 'application/octet-stream';
    
    console.log(`[Upload] Received upload request for key: ${key}`);
    
    if (!key) {
      res.writeHead(400, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: 'Missing key parameter' }));
      return;
    }

    const chunks: Buffer[] = [];
    let uploadSize = 0;
    
    req.on('data', (chunk: Buffer) => {
      uploadSize += chunk.length;
      if (uploadSize > MAX_UPLOAD_SIZE) {
        req.destroy();
        res.writeHead(413, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ error: `File too large (max: ${MAX_UPLOAD_SIZE} bytes)` }));
        return;
      }
      chunks.push(chunk);
    });
    
    req.on('end', async () => {
      try {
        const buffer = Buffer.concat(chunks);
        console.log(`[Upload] Uploading ${buffer.length} bytes to storage: ${key}`);
        await uploadFile(key, buffer, { 'Content-Type': contentType });
        console.log(`[Upload] Successfully uploaded: ${key}`);
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ success: true, key }));
      } catch (err: any) {
        console.error('Upload error:', err);
        res.writeHead(500, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ error: err.message }));
      }
    });
    return;
  }

  // è§¦å‘ç…§ç‰‡å¤„ç†
  if (url.pathname === '/api/process' && req.method === 'POST') {
    try {
      const body = await parseJsonBody(req, MAX_BODY_SIZE);
      const { photoId, albumId, originalKey } = body;
        if (!photoId || !albumId || !originalKey) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing required fields' }));
          return;
        }

      // æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—
      await photoQueue.add('process-photo', { photoId, albumId, originalKey });
      
      res.writeHead(200, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ success: true, message: 'Job queued' }));
    } catch (err: any) {
      console.error('Process queue error:', err);
      const statusCode = err.message?.includes('too large') ? 413 : 
                        err.message?.includes('Invalid JSON') ? 400 : 500;
      res.writeHead(statusCode, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: err.message || 'Internal server error' }));
    }
    return;
  }

  // æ¸…ç†æ–‡ä»¶ï¼ˆç”¨äº cleanup APIï¼‰
  if (url.pathname === '/api/cleanup-file' && req.method === 'POST') {
    try {
      const body = await parseJsonBody(req, MAX_BODY_SIZE);
      const { key } = body;
        if (!key) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing key parameter' }));
          return;
        }

        // å°è¯•åˆ é™¤æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ä¹Ÿä¸ä¼šæŠ¥é”™ï¼‰
        try {
          await deleteFile(key);
          console.log(`[Cleanup] File deleted: ${key}`);
          res.writeHead(200, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ success: true, message: 'File deleted' }));
        } catch (deleteErr: any) {
          // æ–‡ä»¶ä¸å­˜åœ¨æ—¶ä¹Ÿè¿”å›æˆåŠŸï¼ˆå¹‚ç­‰æ“ä½œï¼‰
          if (deleteErr?.code === 'NoSuchKey' || deleteErr?.message?.includes('does not exist')) {
            console.log(`[Cleanup] File not found (already deleted): ${key}`);
            res.writeHead(200, { 'Content-Type': 'application/json' });
            res.end(JSON.stringify({ success: true, message: 'File not found (already deleted)' }));
          } else {
            throw deleteErr;
          }
        }
    } catch (err: any) {
      console.error('[Cleanup] File cleanup error:', err);
      const statusCode = err.message?.includes('too large') ? 413 : 
                        err.message?.includes('Invalid JSON') ? 400 : 500;
      res.writeHead(statusCode, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: err.message || 'Internal server error' }));
    }
    return;
  }

  // ============================================
  // åˆ†ç‰‡ä¸Šä¼  API
  // ============================================

  // åˆå§‹åŒ–åˆ†ç‰‡ä¸Šä¼ 
  if (url.pathname === '/api/multipart/init' && req.method === 'POST') {
    try {
      const body = await parseJsonBody(req, MAX_BODY_SIZE);
      const { key } = body;
        if (!key) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing key' }));
          return;
        }

        console.log(`[Multipart] Initializing upload for key: ${key}`);
        const uploadId = await initMultipartUpload(key);
        console.log(`[Multipart] Initialized upload for ${key}, uploadId: ${uploadId}`);
        
      res.writeHead(200, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ uploadId, key }));
    } catch (err: any) {
      const errorMessage = err?.message || 'Unknown error';
      const errorStack = err?.stack || '';
      console.error('[Multipart] Init error:', errorMessage);
      console.error('[Multipart] Error stack:', errorStack);
      const statusCode = err.message?.includes('too large') ? 413 : 
                        err.message?.includes('Invalid JSON') ? 400 : 500;
      res.writeHead(statusCode, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ 
        error: errorMessage,
        details: process.env.NODE_ENV === 'development' ? errorStack : undefined
      }));
    }
    return;
  }

  // ä¸Šä¼ å•ä¸ªåˆ†ç‰‡
  if (url.pathname === '/api/multipart/upload' && req.method === 'PUT') {
    const key = url.searchParams.get('key');
    const uploadId = url.searchParams.get('uploadId');
    const partNumber = parseInt(url.searchParams.get('partNumber') || '0');

    if (!key || !uploadId || !partNumber) {
      res.writeHead(400, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: 'Missing key, uploadId, or partNumber' }));
      return;
    }

    const chunks: Buffer[] = [];
    let partSize = 0;
    
    req.on('data', (chunk: Buffer) => {
      partSize += chunk.length;
      // å•ä¸ªåˆ†ç‰‡é™åˆ¶ä¸º 100MBï¼ˆS3 æ ‡å‡†ï¼‰
      if (partSize > 100 * 1024 * 1024) {
        req.destroy();
        res.writeHead(413, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ error: 'Part too large (max: 100MB)' }));
        return;
      }
      chunks.push(chunk);
    });
    
    req.on('end', async () => {
      try {
        const buffer = Buffer.concat(chunks);
        console.log(`[Multipart] Uploading part ${partNumber} for ${key}, size: ${buffer.length}`);
        
        const { etag } = await uploadPart(key, uploadId, partNumber, buffer);
        console.log(`[Multipart] Part ${partNumber} uploaded, etag: ${etag}`);
        
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ etag, partNumber }));
      } catch (err: any) {
        console.error('Multipart upload error:', err);
        res.writeHead(500, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ error: err.message }));
      }
    });
    return;
  }

  // å®Œæˆåˆ†ç‰‡ä¸Šä¼ 
  if (url.pathname === '/api/multipart/complete' && req.method === 'POST') {
    try {
      const body = await parseJsonBody(req, MAX_BODY_SIZE);
      const { key, uploadId, parts } = body;
        if (!key || !uploadId || !parts || !Array.isArray(parts)) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing key, uploadId, or parts' }));
          return;
        }

        await completeMultipartUpload(key, uploadId, parts);
        console.log(`[Multipart] Completed upload for ${key}`);
        
      res.writeHead(200, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ success: true, key }));
    } catch (err: any) {
      console.error('Multipart complete error:', err);
      const statusCode = err.message?.includes('too large') ? 413 : 
                        err.message?.includes('Invalid JSON') ? 400 : 500;
      res.writeHead(statusCode, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: err.message || 'Internal server error' }));
    }
    return;
  }

  // å–æ¶ˆåˆ†ç‰‡ä¸Šä¼ 
  if (url.pathname === '/api/multipart/abort' && req.method === 'POST') {
    try {
      const body = await parseJsonBody(req, MAX_BODY_SIZE);
      const { key, uploadId } = body;
        if (!key || !uploadId) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing key or uploadId' }));
          return;
        }

        await abortMultipartUpload(key, uploadId);
        console.log(`[Multipart] Aborted upload for ${key}`);
        
      res.writeHead(200, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ success: true }));
    } catch (err: any) {
      console.error('Multipart abort error:', err);
      const statusCode = err.message?.includes('too large') ? 413 : 
                        err.message?.includes('Invalid JSON') ? 400 : 500;
      res.writeHead(statusCode, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: err.message || 'Internal server error' }));
    }
    return;
  }

  // ============================================
  // æ‰«æåŒæ­¥ API
  // ============================================

  // æ‰«æåŒæ­¥
  if (url.pathname === '/api/scan' && req.method === 'POST') {
    try {
      const body = await parseJsonBody(req, MAX_BODY_SIZE);
      const { albumId } = body;
        if (!albumId) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing albumId' }));
          return;
        }

        console.log(`[Scan] Starting scan for album: ${albumId}`);
        
        // 1. åˆ—å‡º sync/{albumId}/ ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        const prefix = `sync/${albumId}/`;
        const objects = await listObjects(prefix);
        
        // 2. è¿‡æ»¤å‡ºå›¾ç‰‡æ–‡ä»¶
        const imageExtensions = ['.jpg', '.jpeg', '.png', '.heic', '.webp'];
        const imageObjects = objects.filter(obj => {
          const ext = obj.key.toLowerCase().slice(obj.key.lastIndexOf('.'));
          return imageExtensions.includes(ext);
        });

        console.log(`[Scan] Found ${imageObjects.length} images in ${prefix}`);

        if (imageObjects.length === 0) {
          res.writeHead(200, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ 
            success: true, 
            found: 0, 
            added: 0,
            skipped: 0,
            message: 'æœªæ‰¾åˆ°æ–°å›¾ç‰‡' 
          }));
          return;
        }

        // 3. æŸ¥è¯¢æ•°æ®åº“å·²æœ‰çš„æ–‡ä»¶ï¼ˆé€šè¿‡ filename æ¯”å¯¹ï¼‰
        const { data: existingPhotos } = await supabase
          .from('photos')
          .select('filename')
          .eq('album_id', albumId);
        
        const existingFilenames = new Set(
          (existingPhotos || []).map(p => p.filename)
        );

        // 4. å¤„ç†æ–°å›¾ç‰‡
        let addedCount = 0;
        let skippedCount = 0;
        for (const obj of imageObjects) {
          const filename = obj.key.split('/').pop() || '';
          
          // è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
          if (existingFilenames.has(filename)) {
            console.log(`[Scan] Skipping existing: ${filename}`);
            skippedCount++;
            continue;
          }

          // ç”Ÿæˆæ–°çš„ photo_id
          const photoId = crypto.randomUUID();
          const ext = filename.slice(filename.lastIndexOf('.') + 1).toLowerCase();
          const newKey = `raw/${albumId}/${photoId}.${ext}`;

          try {
            // å¤åˆ¶æ–‡ä»¶åˆ°æ ‡å‡†è·¯å¾„
            await copyFile(obj.key, newKey);
            console.log(`[Scan] Copied ${obj.key} -> ${newKey}`);

            // åˆ›å»ºæ•°æ®åº“è®°å½•
            const { error: insertError } = await supabase
              .from('photos')
              .insert({
                id: photoId,
                album_id: albumId,
                original_key: newKey,
                filename: filename,
                file_size: obj.size,
                status: 'pending',
              });

            if (insertError) {
              console.error(`[Scan] Failed to insert photo: ${insertError.message}`);
              // å¦‚æœæ•°æ®åº“æ’å…¥å¤±è´¥ï¼Œåˆ é™¤å·²å¤åˆ¶çš„æ–‡ä»¶
              try {
                await deleteFile(newKey);
              } catch (deleteErr) {
                console.error(`[Scan] Failed to cleanup copied file: ${deleteErr}`);
              }
              continue;
            }

            // æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—
            await photoQueue.add('process-photo', { 
              photoId, 
              albumId, 
              originalKey: newKey 
            });

            // åˆ é™¤åŸå§‹æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œæˆ–ä¿ç•™å¤‡ä»½ï¼‰
            try {
              await deleteFile(obj.key);
            } catch (deleteErr) {
              console.warn(`[Scan] Failed to delete source file ${obj.key}: ${deleteErr}`);
              // ä¸é˜»æ­¢æµç¨‹ç»§ç»­
            }
            
            addedCount++;
          } catch (err: any) {
            console.error(`[Scan] Error processing ${filename}:`, err.message);
            // ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
          }
        }

        console.log(`[Scan] Added ${addedCount} new photos, skipped ${skippedCount}`);

        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ 
          success: true, 
          found: imageObjects.length,
          skipped: skippedCount,
          added: addedCount,
          message: addedCount > 0 
            ? `æˆåŠŸå¯¼å…¥ ${addedCount} å¼ æ–°å›¾ç‰‡${skippedCount > 0 ? `ï¼Œè·³è¿‡ ${skippedCount} å¼ å·²å­˜åœ¨å›¾ç‰‡` : ''}`
            : `æœªæ‰¾åˆ°æ–°å›¾ç‰‡${skippedCount > 0 ? `ï¼Œè·³è¿‡ ${skippedCount} å¼ å·²å­˜åœ¨å›¾ç‰‡` : ''}`
        }));
    } catch (err: any) {
      console.error('[Scan] Error:', err);
      const statusCode = err.message?.includes('too large') ? 413 : 
                        err.message?.includes('Invalid JSON') ? 400 : 500;
      res.writeHead(statusCode, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: err.message || 'Internal server error' }));
    }
    return;
  }

  // 404
  res.writeHead(404, { 'Content-Type': 'application/json' });
  res.end(JSON.stringify({ error: 'Not found' }));
});

// ============================================
// å¯åŠ¨æ—¶æ¢å¤å¡ä½çš„ processing çŠ¶æ€
// ============================================
async function recoverStuckProcessingPhotos() {
  try {
    console.log('ğŸ” Checking for stuck processing photos...');
    
    // 1. æŸ¥è¯¢æ‰€æœ‰çŠ¶æ€ä¸º processing çš„ç…§ç‰‡
    const { data: stuckPhotos, error } = await supabase
      .from('photos')
      .select('id, album_id, original_key, thumb_key, preview_key, status, updated_at')
      .eq('status', 'processing');
    
    if (error) {
      console.error('âŒ Failed to query stuck photos:', error);
      return;
    }
    
    if (!stuckPhotos || stuckPhotos.length === 0) {
      console.log('âœ… No stuck processing photos found');
      return;
    }
    
    console.log(`ğŸ“‹ Found ${stuckPhotos.length} photos stuck in processing state`);
    
    // 2. æ£€æŸ¥é˜Ÿåˆ—ä¸­æ˜¯å¦æœ‰å¯¹åº”çš„ä»»åŠ¡
    const waitingJobs = await photoQueue.getWaiting();
    const activeJobs = await photoQueue.getActive();
    const waitingPhotoIds = new Set(
      [...waitingJobs, ...activeJobs].map(job => job.data.photoId)
    );
    
    let recoveredCount = 0;
    let alreadyCompletedCount = 0;
    let requeuedCount = 0;
    
    // 3. å¤„ç†æ¯ä¸ªå¡ä½çš„ç…§ç‰‡
    for (const photo of stuckPhotos) {
      // å¦‚æœé˜Ÿåˆ—ä¸­æœ‰å¯¹åº”ä»»åŠ¡ï¼Œè·³è¿‡ï¼ˆè¯´æ˜ä»»åŠ¡è¿˜åœ¨å¤„ç†ä¸­ï¼‰
      if (waitingPhotoIds.has(photo.id)) {
        continue;
      }
      
      // æ£€æŸ¥ç…§ç‰‡æ˜¯å¦å·²ç»å¤„ç†å®Œæˆï¼ˆæœ‰ thumb_key å’Œ preview_keyï¼‰
      if (photo.thumb_key && photo.preview_key) {
        // ç…§ç‰‡å·²ç»å¤„ç†å®Œæˆï¼Œä½†çŠ¶æ€æ²¡æœ‰æ›´æ–°ï¼Œä¿®å¤çŠ¶æ€
        const { error: updateError } = await supabase
          .from('photos')
          .update({ status: 'completed' })
          .eq('id', photo.id);
        
        if (updateError) {
          console.error(`âŒ Failed to update photo ${photo.id}:`, updateError);
        } else {
          console.log(`âœ… Recovered completed photo: ${photo.id}`);
          alreadyCompletedCount++;
        }
      } else {
        // ç…§ç‰‡æœªå¤„ç†å®Œæˆï¼Œé‡ç½®ä¸º pending å¹¶é‡æ–°åŠ å…¥é˜Ÿåˆ—
        const { error: updateError } = await supabase
          .from('photos')
          .update({ status: 'pending' })
          .eq('id', photo.id);
        
        if (updateError) {
          console.error(`âŒ Failed to reset photo ${photo.id}:`, updateError);
        } else {
          // é‡æ–°åŠ å…¥é˜Ÿåˆ—
          try {
            await photoQueue.add('process-photo', {
              photoId: photo.id,
              albumId: photo.album_id,
              originalKey: photo.original_key,
            });
            console.log(`ğŸ”„ Requeued photo: ${photo.id}`);
            requeuedCount++;
          } catch (queueError) {
            console.error(`âŒ Failed to requeue photo ${photo.id}:`, queueError);
          }
        }
      }
      recoveredCount++;
    }
    
    console.log(`âœ… Recovery completed: ${recoveredCount} photos processed`);
    console.log(`   - ${alreadyCompletedCount} photos marked as completed`);
    console.log(`   - ${requeuedCount} photos requeued`);
  } catch (err: any) {
    console.error('âŒ Error during recovery:', err);
  }
}

let recoveryTimeout: NodeJS.Timeout | null = null;
let isShuttingDown = false;

// ä¼˜é›…é€€å‡ºå‡½æ•°
async function gracefulShutdown(signal: string) {
  if (isShuttingDown) return;
  isShuttingDown = true;
  
  console.log(`\nğŸ›‘ Received ${signal}, shutting down gracefully...`);
  
  // æ¸…ç†æ¢å¤å®šæ—¶å™¨
  if (recoveryTimeout) {
    clearTimeout(recoveryTimeout);
    recoveryTimeout = null;
  }
  
  // åœæ­¢æ¥å—æ–°è¯·æ±‚
  server.close(() => {
    console.log('âœ… HTTP server closed');
  });
  
  // ç­‰å¾…æ­£åœ¨å¤„ç†çš„ä»»åŠ¡å®Œæˆ
  try {
    await Promise.all([
      worker.close(),
      packageWorker.close(),
      photoQueue.close(),
      packageQueue.close(),
    ]);
    console.log('âœ… All workers and queues closed');
  } catch (err) {
    console.error('âŒ Error closing workers:', err);
  }
  
  console.log('âœ… Graceful shutdown completed');
  process.exit(0);
}

// ç›‘å¬é€€å‡ºä¿¡å·
process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));

// å¤„ç†æœªæ•è·å¼‚å¸¸
process.on('uncaughtException', (err) => {
  console.error('âŒ Uncaught Exception:', err);
  gracefulShutdown('uncaughtException');
});

process.on('unhandledRejection', (reason, promise) => {
  console.error('âŒ Unhandled Rejection at:', promise, 'reason:', reason);
  // ä¸ç«‹å³é€€å‡ºï¼Œè®°å½•é”™è¯¯å³å¯
});

server.listen(HTTP_PORT, () => {
  console.log(`ğŸŒ HTTP API listening on port ${HTTP_PORT}`);
  
  // å¯åŠ¨åå»¶è¿Ÿ5ç§’æ‰§è¡Œæ¢å¤ï¼ˆç­‰å¾…æœåŠ¡å®Œå…¨å¯åŠ¨ï¼‰
  recoveryTimeout = setTimeout(() => {
    recoverStuckProcessingPhotos();
    recoveryTimeout = null;
  }, 5000);
});
