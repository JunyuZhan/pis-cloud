/**
 * PIS Worker - Image Processing Service
 * 
 * @author junyuzhan <junyuzhan@outlook.com>
 * @license MIT
 */

import { config } from 'dotenv';
import { resolve } from 'path';
import { fileURLToPath } from 'url';

// ä»æ ¹ç›®å½•åŠ è½½ .env.localï¼ˆmonorepo ç»Ÿä¸€é…ç½®ï¼‰
const __dirname = fileURLToPath(new URL('.', import.meta.url));
const rootDir = resolve(__dirname, '../../../');
config({ path: resolve(rootDir, '.env.local') });
import http from 'http';
import { Worker, Job, Queue } from 'bullmq';
import { createClient } from '@supabase/supabase-js';
import { connection, QUEUE_NAME, photoQueue } from './lib/redis.js';
import { 
  downloadFile, 
  uploadFile, 
  uploadBuffer,
  initMultipartUpload,
  uploadPart,
  completeMultipartUpload,
  abortMultipartUpload,
  getPresignedGetUrl,
  getPresignedPutUrl,
  listObjects,
  copyFile,
  deleteFile,
  bucketName
} from './lib/storage/index.js';
import { PhotoProcessor } from './processor.js';
import { PackageCreator } from './package-creator.js';

// æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡ (æ”¯æŒä¸¤ç§å˜é‡å)
const supabaseUrl = process.env.SUPABASE_URL || process.env.NEXT_PUBLIC_SUPABASE_URL;
if (!supabaseUrl || !process.env.SUPABASE_SERVICE_ROLE_KEY) {
  console.error('âŒ Missing required environment variables: SUPABASE_URL (or NEXT_PUBLIC_SUPABASE_URL), SUPABASE_SERVICE_ROLE_KEY');
  console.error('   Please configure these values in the root .env.local file');
  process.exit(1);
}

// åˆå§‹åŒ– Supabase å®¢æˆ·ç«¯ (Service Role ç”¨äºåç«¯æ“ä½œ)
const supabase = createClient(
  supabaseUrl,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

interface PhotoJobData {
  photoId: string;
  albumId: string;
  originalKey: string;
}

interface PackageJobData {
  packageId: string;
  albumId: string;
  photoIds: string[];
  includeWatermarked: boolean;
  includeOriginal: boolean;
}

console.log('ğŸš€ PIS Worker Starting...');

const worker = new Worker<PhotoJobData>(
  QUEUE_NAME,
  async (job: Job<PhotoJobData>) => {
    const { photoId, albumId, originalKey } = job.data;
    console.log(`[${job.id}] Processing photo ${photoId} for album ${albumId}`);

    try {
      // 1. æ›´æ–°çŠ¶æ€ä¸º processing
      await supabase
        .from('photos')
        .update({ status: 'processing' })
        .eq('id', photoId);

      // 2. ä»å­˜å‚¨ä¸‹è½½åŸå›¾
      console.time(`[${job.id}] Download`);
      const originalBuffer = await downloadFile(originalKey);
      console.timeEnd(`[${job.id}] Download`);

      // 3. è·å–ç…§ç‰‡çš„æ‰‹åŠ¨æ—‹è½¬è§’åº¦
      const { data: photo } = await supabase
        .from('photos')
        .select('rotation')
        .eq('id', photoId)
        .single();

      // 4. è·å–ç›¸å†Œæ°´å°é…ç½®
      const { data: album } = await supabase
        .from('albums')
        .select('watermark_enabled, watermark_type, watermark_config')
        .eq('id', albumId)
        .single();

      // æ„å»ºæ°´å°é…ç½®ï¼ˆæ”¯æŒæ–°æ—§æ ¼å¼ï¼‰
      const watermarkConfigRaw = (album?.watermark_config as any) || {};
      const watermarkConfig = {
        enabled: album?.watermark_enabled ?? false,
        // å¦‚æœåŒ…å« watermarks æ•°ç»„ï¼Œä½¿ç”¨æ–°æ ¼å¼
        watermarks: watermarkConfigRaw.watermarks || undefined,
        // å…¼å®¹æ—§æ ¼å¼
        type: album?.watermark_type ?? watermarkConfigRaw.type ?? 'text',
        text: watermarkConfigRaw.text,
        logoUrl: watermarkConfigRaw.logoUrl,
        opacity: watermarkConfigRaw.opacity ?? 0.5,
        position: watermarkConfigRaw.position ?? 'center',
      };

      // 5. å¤„ç†å›¾ç‰‡ (Sharp)
      console.time(`[${job.id}] Process`);
      const processor = new PhotoProcessor(originalBuffer);
      const result = await processor.process(watermarkConfig, photo?.rotation ?? null);
      console.timeEnd(`[${job.id}] Process`);

      // 6. ä¸Šä¼ å¤„ç†åçš„å›¾ç‰‡åˆ°å­˜å‚¨
      const thumbKey = `processed/thumbs/${albumId}/${photoId}.jpg`;
      const previewKey = `processed/previews/${albumId}/${photoId}.jpg`;

      console.time(`[${job.id}] Upload`);
      await Promise.all([
        uploadFile(thumbKey, result.thumbBuffer, { 'Content-Type': 'image/jpeg' }),
        uploadFile(previewKey, result.previewBuffer, { 'Content-Type': 'image/jpeg' }),
      ]);
      console.timeEnd(`[${job.id}] Upload`);

      // 7. æ›´æ–°æ•°æ®åº“
      const { error } = await supabase
        .from('photos')
        .update({
          status: 'completed',
          thumb_key: thumbKey,
          preview_key: previewKey,
          width: result.metadata.width,
          height: result.metadata.height,
          blur_data: result.blurHash,
          exif: result.exif,
          file_size: originalBuffer.length,
          mime_type: result.metadata.format,
          // å°è¯•ä» EXIF è·å–æ‹æ‘„æ—¶é—´ï¼Œå¦åˆ™ç”¨å½“å‰æ—¶é—´
          captured_at: result.exif?.exif?.DateTimeOriginal || new Date().toISOString(),
          // æ›´æ–°æ—¶é—´æˆ³ï¼ˆç”¨äºå‰ç«¯ç¼“å­˜ç ´åï¼‰
          updated_at: new Date().toISOString(),
        })
        .eq('id', photoId);

      if (error) throw error;

      // 8. æ›´æ–°ç›¸å†Œç…§ç‰‡æ•°é‡
      const { count } = await supabase
        .from('photos')
        .select('*', { count: 'exact', head: true })
        .eq('album_id', albumId)
        .eq('status', 'completed');
      
      await supabase
        .from('albums')
        .update({ photo_count: count || 0 })
        .eq('id', albumId);

      console.log(`[${job.id}] Completed successfully`);
    } catch (err: any) {
      console.error(`[${job.id}] Failed:`, err);
      
      // æ›´æ–°çŠ¶æ€ä¸º failed
      await supabase
        .from('photos')
        .update({ status: 'failed' })
        .eq('id', photoId);
      
      throw err; // è®© BullMQ çŸ¥é“ä»»åŠ¡å¤±è´¥ (ä»¥ä¾¿é‡è¯•)
    }
  },
  {
    connection,
    concurrency: 5, // é€‚å½“å¢åŠ å¹¶å‘
    limiter: {
      max: 10,
      duration: 1000,
    },
  }
);

worker.on('failed', (job, err) => {
  console.error(`âŒ Job ${job?.id} failed:`, err.message);
});

console.log(`âœ… Worker listening on queue: ${QUEUE_NAME}`);

// ============================================
// æ‰“åŒ…ä¸‹è½½ Worker
// ============================================
const packageQueue = new Queue('package-downloads', { connection });

const packageWorker = new Worker<PackageJobData>(
  'package-downloads',
  async (job: Job<PackageJobData>) => {
    const { packageId, albumId, photoIds, includeWatermarked, includeOriginal } = job.data;
    console.log(`[Package ${job.id}] Processing package ${packageId} for album ${albumId}`);

    try {
      // 1. æ›´æ–°çŠ¶æ€ä¸º processing
      await supabase
        .from('package_downloads')
        .update({ status: 'processing' })
        .eq('id', packageId);

      // 2. è·å–ç›¸å†Œæ°´å°é…ç½®å’Œæ ‡é¢˜
      const { data: album } = await supabase
        .from('albums')
        .select('title, watermark_enabled, watermark_type, watermark_config')
        .eq('id', albumId)
        .single();

      const watermarkConfig = album?.watermark_enabled
        ? {
            enabled: true,
            type: album.watermark_type || 'text',
            ...((album.watermark_config as any) || {}),
          }
        : undefined;

      // 3. è·å–ç…§ç‰‡ä¿¡æ¯
      const { data: photos } = await supabase
        .from('photos')
        .select('id, filename, original_key, preview_key')
        .in('id', photoIds)
        .eq('status', 'completed');

      if (!photos || photos.length === 0) {
        throw new Error('No photos found');
      }

      // 4. åˆ›å»º ZIP åŒ…
      console.time(`[Package ${job.id}] Create ZIP`);
      const zipBuffer = await PackageCreator.createPackage({
        photos: photos.map(p => ({
          id: p.id,
          filename: p.filename,
          originalKey: p.original_key,
          previewKey: p.preview_key,
        })),
        albumId,
        watermarkConfig,
        includeWatermarked,
        includeOriginal,
      });
      console.timeEnd(`[Package ${job.id}] Create ZIP`);

      // 5. ä¸Šä¼  ZIP åˆ°å­˜å‚¨
      const zipKey = `packages/${albumId}/${packageId}.zip`;
      const albumTitle = (album as any)?.title || 'photos';
      console.time(`[Package ${job.id}] Upload ZIP`);
      await uploadFile(zipKey, zipBuffer, {
        'Content-Type': 'application/zip',
        'Content-Disposition': `attachment; filename="${albumTitle}.zip"`,
      });
      console.timeEnd(`[Package ${job.id}] Upload ZIP`);

      // 6. ç”Ÿæˆä¸‹è½½é“¾æ¥ï¼ˆ15å¤©æœ‰æ•ˆæœŸï¼‰
      const expiresAt = new Date();
      expiresAt.setDate(expiresAt.getDate() + 15);
      const downloadUrl = await getPresignedGetUrl(zipKey, 15 * 24 * 60 * 60); // 15å¤©

      // 7. æ›´æ–°æ•°æ®åº“
      await supabase
        .from('package_downloads')
        .update({
          status: 'completed',
          zip_key: zipKey,
          file_size: zipBuffer.length,
          download_url: downloadUrl,
          expires_at: expiresAt.toISOString(),
          completed_at: new Date().toISOString(),
        })
        .eq('id', packageId);

      console.log(`[Package ${job.id}] Completed successfully`);
    } catch (err: any) {
      console.error(`[Package ${job.id}] Failed:`, err);

      // æ›´æ–°çŠ¶æ€ä¸º failed
      await supabase
        .from('package_downloads')
        .update({ status: 'failed' })
        .eq('id', packageId);

      throw err;
    }
  },
  {
    connection,
    concurrency: 2, // æ‰“åŒ…ä»»åŠ¡å¹¶å‘æ•°è¾ƒä½ï¼Œå› ä¸ºèµ„æºæ¶ˆè€—å¤§
  }
);

packageWorker.on('failed', (job, err) => {
  console.error(`âŒ Package job ${job?.id} failed:`, err.message);
});

console.log(`âœ… Package worker listening on queue: package-downloads`);

// ============================================
// HTTP API æœåŠ¡å™¨ (ç”¨äºæ¥æ”¶ä¸Šä¼ è¯·æ±‚)
// ============================================

const HTTP_PORT = parseInt(process.env.HTTP_PORT || '3001');

const server = http.createServer(async (req, res) => {
  // CORS
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, PUT, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (req.method === 'OPTIONS') {
    res.writeHead(204);
    res.end();
    return;
  }

  const url = new URL(req.url || '/', `http://localhost:${HTTP_PORT}`);

  // å¥åº·æ£€æŸ¥
  if (url.pathname === '/health') {
    const health: any = {
      status: 'ok',
      timestamp: new Date().toISOString(),
      services: {}
    };

    // æ£€æŸ¥ Redis è¿æ¥ï¼ˆé€šè¿‡é˜Ÿåˆ—æµ‹è¯•ï¼‰
    try {
      const testQueue = new Queue('health-check', { connection });
      await testQueue.getWaitingCount(); // è½»é‡çº§æ“ä½œæµ‹è¯•è¿æ¥
      await testQueue.close();
      health.services.redis = { status: 'ok' };
    } catch (err: any) {
      health.services.redis = { status: 'error', error: err.message };
      health.status = 'degraded';
    }

    // æ£€æŸ¥ Supabase è¿æ¥
    try {
      const { error } = await supabase.from('albums').select('id').limit(1);
      if (error) throw error;
      health.services.supabase = { status: 'ok' };
    } catch (err: any) {
      health.services.supabase = { status: 'error', error: err.message };
      health.status = 'degraded';
    }

    // æ£€æŸ¥å­˜å‚¨è¿æ¥
    try {
      const storageModule = await import('./lib/storage/index.js');
      const testKey = `health-check-${Date.now()}.txt`;
      // å°è¯•åˆ—å‡º bucketï¼ˆè½»é‡çº§æ“ä½œï¼‰
      health.services.storage = { 
        status: 'ok', 
        bucket: storageModule.bucketName,
        type: process.env.STORAGE_TYPE || 'minio'
      };
    } catch (err: any) {
      health.services.storage = { status: 'error', error: err.message };
      health.status = 'degraded';
    }

    const statusCode = health.status === 'ok' ? 200 : 503;
    res.writeHead(statusCode, { 'Content-Type': 'application/json' });
    res.end(JSON.stringify(health));
    return;
  }

  // è·å–é¢„ç­¾åä¸Šä¼  URL (ä¿ç•™å…¼å®¹)
  if (url.pathname === '/api/presign' && req.method === 'POST') {
    let body = '';
    req.on('data', chunk => body += chunk);
    req.on('end', async () => {
      try {
        const { key } = JSON.parse(body);
        if (!key) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing key' }));
          return;
        }

        const presignedUrl = await getPresignedPutUrl(key);
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ url: presignedUrl }));
      } catch (err: any) {
        console.error('Presign error:', err);
        res.writeHead(500, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ error: err.message }));
      }
    });
    return;
  }

  // ç›´æ¥ä¸Šä¼ æ–‡ä»¶åˆ° MinIO (ä»£ç†æ¨¡å¼)
  if (url.pathname === '/api/upload' && req.method === 'PUT') {
    const key = url.searchParams.get('key');
    const contentType = req.headers['content-type'] || 'application/octet-stream';
    
    console.log(`[Upload] Received upload request for key: ${key}`);
    
    if (!key) {
      res.writeHead(400, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: 'Missing key parameter' }));
      return;
    }

    const chunks: Buffer[] = [];
    req.on('data', chunk => chunks.push(chunk));
    req.on('end', async () => {
      try {
        const buffer = Buffer.concat(chunks);
        console.log(`[Upload] Uploading ${buffer.length} bytes to storage: ${key}`);
        await uploadFile(key, buffer, { 'Content-Type': contentType });
        console.log(`[Upload] Successfully uploaded: ${key}`);
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ success: true, key }));
      } catch (err: any) {
        console.error('Upload error:', err);
        res.writeHead(500, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ error: err.message }));
      }
    });
    return;
  }

  // è§¦å‘ç…§ç‰‡å¤„ç†
  if (url.pathname === '/api/process' && req.method === 'POST') {
    let body = '';
    req.on('data', chunk => body += chunk);
    req.on('end', async () => {
      try {
        const { photoId, albumId, originalKey } = JSON.parse(body);
        if (!photoId || !albumId || !originalKey) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing required fields' }));
          return;
        }

        // æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—
        await photoQueue.add('process-photo', { photoId, albumId, originalKey });
        
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ success: true, message: 'Job queued' }));
      } catch (err: any) {
        console.error('Process queue error:', err);
        res.writeHead(500, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ error: err.message }));
      }
    });
    return;
  }

  // ============================================
  // åˆ†ç‰‡ä¸Šä¼  API
  // ============================================

  // åˆå§‹åŒ–åˆ†ç‰‡ä¸Šä¼ 
  if (url.pathname === '/api/multipart/init' && req.method === 'POST') {
    let body = '';
    req.on('data', chunk => body += chunk);
    req.on('end', async () => {
      try {
        const { key } = JSON.parse(body);
        if (!key) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing key' }));
          return;
        }

        console.log(`[Multipart] Initializing upload for key: ${key}`);
        const uploadId = await initMultipartUpload(key);
        console.log(`[Multipart] Initialized upload for ${key}, uploadId: ${uploadId}`);
        
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ uploadId, key }));
      } catch (err: any) {
        const errorMessage = err?.message || 'Unknown error';
        const errorStack = err?.stack || '';
        console.error('[Multipart] Init error:', errorMessage);
        console.error('[Multipart] Error stack:', errorStack);
        res.writeHead(500, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ 
          error: errorMessage,
          details: process.env.NODE_ENV === 'development' ? errorStack : undefined
        }));
      }
    });
    return;
  }

  // ä¸Šä¼ å•ä¸ªåˆ†ç‰‡
  if (url.pathname === '/api/multipart/upload' && req.method === 'PUT') {
    const key = url.searchParams.get('key');
    const uploadId = url.searchParams.get('uploadId');
    const partNumber = parseInt(url.searchParams.get('partNumber') || '0');

    if (!key || !uploadId || !partNumber) {
      res.writeHead(400, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: 'Missing key, uploadId, or partNumber' }));
      return;
    }

    const chunks: Buffer[] = [];
    req.on('data', chunk => chunks.push(chunk));
    req.on('end', async () => {
      try {
        const buffer = Buffer.concat(chunks);
        console.log(`[Multipart] Uploading part ${partNumber} for ${key}, size: ${buffer.length}`);
        
        const { etag } = await uploadPart(key, uploadId, partNumber, buffer);
        console.log(`[Multipart] Part ${partNumber} uploaded, etag: ${etag}`);
        
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ etag, partNumber }));
      } catch (err: any) {
        console.error('Multipart upload error:', err);
        res.writeHead(500, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ error: err.message }));
      }
    });
    return;
  }

  // å®Œæˆåˆ†ç‰‡ä¸Šä¼ 
  if (url.pathname === '/api/multipart/complete' && req.method === 'POST') {
    let body = '';
    req.on('data', chunk => body += chunk);
    req.on('end', async () => {
      try {
        const { key, uploadId, parts } = JSON.parse(body);
        if (!key || !uploadId || !parts || !Array.isArray(parts)) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing key, uploadId, or parts' }));
          return;
        }

        await completeMultipartUpload(key, uploadId, parts);
        console.log(`[Multipart] Completed upload for ${key}`);
        
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ success: true, key }));
      } catch (err: any) {
        console.error('Multipart complete error:', err);
        res.writeHead(500, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ error: err.message }));
      }
    });
    return;
  }

  // å–æ¶ˆåˆ†ç‰‡ä¸Šä¼ 
  if (url.pathname === '/api/multipart/abort' && req.method === 'POST') {
    let body = '';
    req.on('data', chunk => body += chunk);
    req.on('end', async () => {
      try {
        const { key, uploadId } = JSON.parse(body);
        if (!key || !uploadId) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing key or uploadId' }));
          return;
        }

        await abortMultipartUpload(key, uploadId);
        console.log(`[Multipart] Aborted upload for ${key}`);
        
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ success: true }));
      } catch (err: any) {
        console.error('Multipart abort error:', err);
        res.writeHead(500, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ error: err.message }));
      }
    });
    return;
  }

  // ============================================
  // æ‰«æåŒæ­¥ API
  // ============================================

  // æ‰«æåŒæ­¥
  if (url.pathname === '/api/scan' && req.method === 'POST') {
    let body = '';
    req.on('data', chunk => body += chunk);
    req.on('end', async () => {
      try {
        const { albumId } = JSON.parse(body);
        if (!albumId) {
          res.writeHead(400, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ error: 'Missing albumId' }));
          return;
        }

        console.log(`[Scan] Starting scan for album: ${albumId}`);
        
        // 1. åˆ—å‡º sync/{albumId}/ ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        const prefix = `sync/${albumId}/`;
        const objects = await listObjects(prefix);
        
        // 2. è¿‡æ»¤å‡ºå›¾ç‰‡æ–‡ä»¶
        const imageExtensions = ['.jpg', '.jpeg', '.png', '.heic', '.webp'];
        const imageObjects = objects.filter(obj => {
          const ext = obj.key.toLowerCase().slice(obj.key.lastIndexOf('.'));
          return imageExtensions.includes(ext);
        });

        console.log(`[Scan] Found ${imageObjects.length} images in ${prefix}`);

        if (imageObjects.length === 0) {
          res.writeHead(200, { 'Content-Type': 'application/json' });
          res.end(JSON.stringify({ 
            success: true, 
            found: 0, 
            added: 0,
            skipped: 0,
            message: 'æœªæ‰¾åˆ°æ–°å›¾ç‰‡' 
          }));
          return;
        }

        // 3. æŸ¥è¯¢æ•°æ®åº“å·²æœ‰çš„æ–‡ä»¶ï¼ˆé€šè¿‡ filename æ¯”å¯¹ï¼‰
        const { data: existingPhotos } = await supabase
          .from('photos')
          .select('filename')
          .eq('album_id', albumId);
        
        const existingFilenames = new Set(
          (existingPhotos || []).map(p => p.filename)
        );

        // 4. å¤„ç†æ–°å›¾ç‰‡
        let addedCount = 0;
        let skippedCount = 0;
        for (const obj of imageObjects) {
          const filename = obj.key.split('/').pop() || '';
          
          // è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
          if (existingFilenames.has(filename)) {
            console.log(`[Scan] Skipping existing: ${filename}`);
            skippedCount++;
            continue;
          }

          // ç”Ÿæˆæ–°çš„ photo_id
          const photoId = crypto.randomUUID();
          const ext = filename.slice(filename.lastIndexOf('.') + 1).toLowerCase();
          const newKey = `raw/${albumId}/${photoId}.${ext}`;

          try {
            // å¤åˆ¶æ–‡ä»¶åˆ°æ ‡å‡†è·¯å¾„
            await copyFile(obj.key, newKey);
            console.log(`[Scan] Copied ${obj.key} -> ${newKey}`);

            // åˆ›å»ºæ•°æ®åº“è®°å½•
            const { error: insertError } = await supabase
              .from('photos')
              .insert({
                id: photoId,
                album_id: albumId,
                original_key: newKey,
                filename: filename,
                file_size: obj.size,
                status: 'pending',
              });

            if (insertError) {
              console.error(`[Scan] Failed to insert photo: ${insertError.message}`);
              // å¦‚æœæ•°æ®åº“æ’å…¥å¤±è´¥ï¼Œåˆ é™¤å·²å¤åˆ¶çš„æ–‡ä»¶
              try {
                await deleteFile(newKey);
              } catch (deleteErr) {
                console.error(`[Scan] Failed to cleanup copied file: ${deleteErr}`);
              }
              continue;
            }

            // æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—
            await photoQueue.add('process-photo', { 
              photoId, 
              albumId, 
              originalKey: newKey 
            });

            // åˆ é™¤åŸå§‹æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œæˆ–ä¿ç•™å¤‡ä»½ï¼‰
            try {
              await deleteFile(obj.key);
            } catch (deleteErr) {
              console.warn(`[Scan] Failed to delete source file ${obj.key}: ${deleteErr}`);
              // ä¸é˜»æ­¢æµç¨‹ç»§ç»­
            }
            
            addedCount++;
          } catch (err: any) {
            console.error(`[Scan] Error processing ${filename}:`, err.message);
            // ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
          }
        }

        console.log(`[Scan] Added ${addedCount} new photos, skipped ${skippedCount}`);

        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ 
          success: true, 
          found: imageObjects.length,
          skipped: skippedCount,
          added: addedCount,
          message: addedCount > 0 
            ? `æˆåŠŸå¯¼å…¥ ${addedCount} å¼ æ–°å›¾ç‰‡${skippedCount > 0 ? `ï¼Œè·³è¿‡ ${skippedCount} å¼ å·²å­˜åœ¨å›¾ç‰‡` : ''}`
            : `æœªæ‰¾åˆ°æ–°å›¾ç‰‡${skippedCount > 0 ? `ï¼Œè·³è¿‡ ${skippedCount} å¼ å·²å­˜åœ¨å›¾ç‰‡` : ''}`
        }));
      } catch (err: any) {
        console.error('[Scan] Error:', err);
        res.writeHead(500, { 'Content-Type': 'application/json' });
        res.end(JSON.stringify({ error: err.message }));
      }
    });
    return;
  }

  // 404
  res.writeHead(404, { 'Content-Type': 'application/json' });
  res.end(JSON.stringify({ error: 'Not found' }));
});

server.listen(HTTP_PORT, () => {
  console.log(`ğŸŒ HTTP API listening on port ${HTTP_PORT}`);
});

// ä¼˜é›…é€€å‡º
process.on('SIGTERM', async () => {
  server.close();
  await worker.close();
});
